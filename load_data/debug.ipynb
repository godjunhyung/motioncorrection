{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def bin_iqm(df, column_name):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    data = df_copy[column_name]\n",
    "    \n",
    "    counts, bin_edges = np.histogram(data, bins=100, range=(data.min(), data.max()))\n",
    "    bin_indices = np.digitize(data, bins=bin_edges[:-1], right=False) - 1\n",
    "\n",
    "    bin_indices = np.clip(bin_indices, 0, 99)\n",
    "\n",
    "    df_copy[column_name] = bin_indices\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def load_data_and_labels(csv_path, iqm_label):\n",
    "    \"\"\"\n",
    "    Load data, labels, and sequence information for all predefined sequences.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file containing slice information.\n",
    "        iqm_label (str): The label (e.g., \"Haarpsi\", \"VSI\", \"VIF\", \"NQM\") to use.\n",
    "\n",
    "    Returns:\n",
    "        data (list): List of loaded NumPy arrays for slices.\n",
    "        labels (list): Corresponding labels for the slices.\n",
    "        sequences (list): Sequence information for each slice.\n",
    "    \"\"\"\n",
    "    # Define the four sequences\n",
    "    sequences_to_process = [\"t1\", \"t2\", \"t1post\", \"flair\"]\n",
    "\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[(df[\"Slice Index\"] < 10)]\n",
    "    binned_df = bin_iqm(df, iqm_label)\n",
    "\n",
    "    # Prepare lists to store data, labels, and sequences\n",
    "    data = []\n",
    "    labels = []\n",
    "    sequences = []\n",
    "\n",
    "    for sequence in sequences_to_process:\n",
    "        # Filter the DataFrame based on sequence\n",
    "        filtered_df = binned_df[(binned_df[\"sequence\"] == sequence)]\n",
    "\n",
    "        # Process motion sequences\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            subject_id = row[\"Subject ID\"]\n",
    "            slice_idx = row[\"Slice Index\"]\n",
    "            motion_level = row[\"Motion_Level\"]\n",
    "\n",
    "            # Construct the path to the motion data\n",
    "            data_path = f\"data/{sequence}_g{motion_level}/{subject_id}_motion.npy\"\n",
    "            if os.path.exists(data_path):\n",
    "                slice_data = np.load(data_path)[slice_idx]  # Load specific slice\n",
    "                data.append(slice_data)\n",
    "                labels.append(row[iqm_label])\n",
    "                sequences.append(sequence)\n",
    "\n",
    "        # Process clear sequences (label = 100)\n",
    "        unique_subjects = filtered_df[\"Subject ID\"].unique()\n",
    "        for subject_id in unique_subjects:\n",
    "            clear_path = f\"data/{sequence}_clear/{subject_id}.npy\"\n",
    "            if os.path.exists(clear_path):\n",
    "                clear_data = np.load(clear_path)\n",
    "                for slice_idx in range(min(10, clear_data.shape[0])):  # Use slices < 10\n",
    "                    data.append(clear_data[slice_idx])\n",
    "                    labels.append(100)  # Clear sequences have label = 100\n",
    "                    sequences.append(sequence)\n",
    "\n",
    "    return data, labels, sequences\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, iqm_label, load_feats=None):\n",
    "\n",
    "        self.X, self.y = load_data_and_labels(csv_path, iqm_label)\n",
    "        \n",
    "        self.bias_feats = None\n",
    "\n",
    "        if load_feats:\n",
    "            print(\"Loading biased features\", load_feats)\n",
    "            self.bias_feats = torch.load(load_feats, map_location=\"cpu\")\n",
    "        \n",
    "        print(f\"Read {len(self.X)} records\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        x = self.X[index]\n",
    "        y = self.y[index]\n",
    "        iqm, sequence = y[0], y[1]\n",
    "        \n",
    "        if self.bias_feats is not None:\n",
    "            return x, iqm, self.bias_feats[index]\n",
    "        else:\n",
    "            return x, iqm, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/root/motioncorrection/iqm_csv/fr-iqm.csv\"\n",
    "iqm_label = \"VIF\"\n",
    "train_loader = torch.utils.data.DataLoader(CustomDataset(csv_path, iqm_label),\n",
    "                                               batch_size=3, shuffle=True, num_workers=8,\n",
    "                                               persistent_workers=True)\n",
    "    \n",
    "x, y1, y2 = next(iter(train_loader))\n",
    "print(x.shape, y1, y2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
